{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBQAbxIu104vYjmwT5BYp5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smitike/REU-AI-Cybersecurity-SM/blob/main/REU_AI_Cybersecurity_SM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qisk has comprehensive ecosystem and support for quantum machine learning through libraries like Qiskit Machine Learning. Easy access to quantum hardware for practical experiments through.\n",
        "\n",
        "Install Qiskit"
      ],
      "metadata": {
        "id": "KoU3q0u1S8og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare environment"
      ],
      "metadata": {
        "id": "j6rqNPOFt9M4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vbPJ-BmSRAG",
        "outputId": "ad9f4b72-eacd-46a3-a701-9a82d5cffc9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.14.2)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.11.4)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.12.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.1)\n",
            "Requirement already satisfied: symengine>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit) (6.0.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and Run a Quantum Circuit"
      ],
      "metadata": {
        "id": "HTy3J9EmVWWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary Qiskit components\n",
        "from qiskit import QuantumCircuit, transpile, assemble\n",
        "from qiskit.visualization import plot_histogram\n",
        "\n",
        "# Create a Quantum Circuit with 1 qubit and 1 classical bit\n",
        "qc = QuantumCircuit(1, 1)\n",
        "\n",
        "# Apply a Hadamard gate to the qubit\n",
        "qc.h(0)\n",
        "\n",
        "# Measure the qubit\n",
        "qc.measure(0, 0)\n",
        "\n",
        "# Visualize the circuit\n",
        "qc.draw('mpl')\n",
        "\n",
        "# Use Aer's qasm_simulator\n",
        "simulator = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "# Transpile the circuit for the simulator\n",
        "compiled_circuit = transpile(qc, simulator)\n",
        "\n",
        "# Assemble the circuit into a Qobj\n",
        "qobj = assemble(compiled_circuit)\n",
        "\n",
        "# Run the simulation and get the result\n",
        "result = simulator.run(qobj).result()\n",
        "\n",
        "# Get the counts (number of times each result was measured)\n",
        "counts = result.get_counts(qc)\n",
        "\n",
        "# Plot the results as a histogram\n",
        "plot_histogram(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "51cVM-riVXYi",
        "outputId": "ad0bb434-b417-445a-dd33-5a98936ab617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MissingOptionalLibraryError",
          "evalue": "\"The 'pylatexenc' library is required to use 'MatplotlibDrawer'. You can install it with 'pip install pylatexenc'.\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMissingOptionalLibraryError\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-47fb487cff82>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Visualize the circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mqc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mpl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Use Aer's qasm_simulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/circuit/quantumcircuit.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, output, scale, filename, style, interactive, plot_barriers, reverse_bits, justify, vertical_compression, idle_wires, with_layout, fold, ax, initial_state, cregbundle, wire_order, expr_len)\u001b[0m\n\u001b[1;32m   3261\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcircuit_drawer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m         return circuit_drawer(\n\u001b[0m\u001b[1;32m   3264\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m             \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/visualization/circuit/circuit_visualization.py\u001b[0m in \u001b[0;36mcircuit_drawer\u001b[0;34m(circuit, scale, filename, style, output, interactive, plot_barriers, reverse_bits, justify, vertical_compression, idle_wires, with_layout, fold, ax, initial_state, cregbundle, wire_order, expr_len)\u001b[0m\n\u001b[1;32m    321\u001b[0m         )\n\u001b[1;32m    322\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mpl\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         image = _matplotlib_circuit_drawer(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/visualization/circuit/circuit_visualization.py\u001b[0m in \u001b[0;36m_matplotlib_circuit_drawer\u001b[0;34m(circuit, scale, filename, style, plot_barriers, reverse_bits, justify, idle_wires, with_layout, fold, ax, initial_state, cregbundle, wire_order, expr_len)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m     qcd = _matplotlib.MatplotlibDrawer(\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0mqubits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mclbits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/utils/classtools.py\u001b[0m in \u001b[0;36mout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/utils/lazy_tester.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_now\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/utils/lazy_tester.py\u001b[0m in \u001b[0;36mrequire_now\u001b[0;34m(self, feature)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         raise MissingOptionalLibraryError(\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0mlibname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpip_install\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_install\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_msg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         )\n",
            "\u001b[0;31mMissingOptionalLibraryError\u001b[0m: \"The 'pylatexenc' library is required to use 'MatplotlibDrawer'. You can install it with 'pip install pylatexenc'.\"",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Pytorch"
      ],
      "metadata": {
        "id": "KQxzmQVUXjox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA-D1QOITGF4",
        "outputId": "e2f09052-fe73-469b-9a1c-39bede2f810d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# Define a simple neural network\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the network and move it to the device\n",
        "net = Net().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Define a simple transformation for the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(2):\n",
        "    # Train for 2 epochs\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(net.state_dict(), 'simple_net.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "6T-Rwnq4XzdS",
        "outputId": "008ba7b8-e38c-421e-f839-ac6ff0a3b8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9dd05be6d651>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Define a simple transformation for the MNIST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Load the MNIST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "ntegrate a quantum layer using PennyLane with a classical deep learning model"
      ],
      "metadata": {
        "id": "If6hOMt5a5ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN7Bros0a-vx",
        "outputId": "9e931c0f-160a-44cb-b15f-56a8c8e5538c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.36.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.3)\n",
            "Collecting rustworkx (from pennylane)\n",
            "  Downloading rustworkx-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.6.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting semantic-version>=2.7 (from pennylane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autoray>=0.6.1 (from pennylane)\n",
            "  Downloading autoray-0.6.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.3)\n",
            "Collecting pennylane-lightning>=0.36 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.6.2)\n",
            "Installing collected packages: appdirs, semantic-version, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.6.12 pennylane-0.36.0 pennylane-lightning-0.36.0 rustworkx-0.14.2 semantic-version-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define a quantum device\n",
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum layer\n",
        "@qml.qnode(dev)\n",
        "def quantum_layer(inputs):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(inputs[i], wires=i)\n",
        "    for i in range(n_qubits):\n",
        "        qml.CNOT(wires=[i, (i+1) % n_qubits])\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "# Integrate quantum layer with Keras\n",
        "class QuantumLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(QuantumLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.convert_to_tensor([quantum_layer(inputs)], dtype=tf.float32)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(QuantumLayer())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model (using a sample dataset)\n",
        "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "# model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "_n9X1EBla0Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting Feature"
      ],
      "metadata": {
        "id": "s-PRTrktbMMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import Aer\n",
        "from qiskit_optimization import QuadraticProgram\n",
        "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
        "from qiskit_optimization.translators import from_qubo\n",
        "from qiskit.algorithms import QAOA\n",
        "from qiskit.utils import algorithm_globals, QuantumInstance\n",
        "from qiskit.providers.aer import AerSimulator\n",
        "\n",
        "# Define the number of features\n",
        "num_features = 10\n",
        "\n",
        "# Initialize a Quadratic Program, Specifies the number of features to select.\n",
        "qp = QuadraticProgram()\n",
        "\n",
        "# Add binary variables representing feature selection\n",
        "for i in range(num_features):\n",
        "    qp.binary_var(name=f'x{i}')\n",
        "\n",
        "# Example weights and interactions (you need to define these based on your data)\n",
        "weights = [0.5, 0.6, 0.4, 0.7, 0.3, 0.8, 0.2, 0.9, 0.1, 0.5]\n",
        "interactions = {(i, j): 0.01 for i in range(num_features) for j in range(i+1, num_features)}\n",
        "\n",
        "# Objective function: Maximize sum of selected feature weights and interactions\n",
        "objective = sum(weights[i] * qp.binary_var(f'x{i}') for i in range(num_features))\n",
        "objective += sum(interactions[(i, j)] * qp.binary_var(f'x{i}') * qp.binary_var(f'x{j}') for i, j in interactions)\n",
        "\n",
        "# Add objective to the Quadratic Program\n",
        "qp.maximize(linear=[weights[i] for i in range(num_features)], quadratic=interactions)\n",
        "\n",
        "# If you want to constrain the number of features selected, add a constraint\n",
        "k = 5  # Number of features to select\n",
        "qp.linear_constraint(linear={f'x{i}': 1 for i in range(num_features)}, sense='==', rhs=k)\n",
        "\n",
        "# Convert the Quadratic Program to a QUBO\n",
        "qubo = qp.to_qubo()\n",
        "\n",
        "# Setup QAOA\n",
        "backend = AerSimulator()\n",
        "quantum_instance = QuantumInstance(backend, seed_simulator=algorithm_globals.random_seed, seed_transpiler=algorithm_globals.random_seed)\n",
        "qaoa = QAOA(quantum_instance=quantum_instance)\n",
        "optimizer = MinimumEigenOptimizer(qaoa)\n",
        "\n",
        "# Solve the QUBO problem using QAOA\n",
        "result = optimizer.solve(qp)\n",
        "\n",
        "# Extract selected features\n",
        "selected_features = [i for i, x in enumerate(result.x) if x == 1]\n",
        "\n",
        "print(\"Selected Features:\", selected_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "jDHaq3oRbK-T",
        "outputId": "c427a681-6a31-472d-e580-a263f3f3d550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'qiskit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-36eb2a9b420b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_optimization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuadraticProgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinimumEigenOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_qubo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQAOA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiskit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection and Preprocessing"
      ],
      "metadata": {
        "id": "gf3OPuZyuA0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Load dataset from csv file\n",
        "data = pd.read_csv('rootkit_malware_dataset.csv')\n",
        "\n",
        "# Remove duplicates\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Handle missing values\n",
        "data.fillna(method='ffill', inplace=True)\n",
        "\n",
        "#extract from the three columns using CountVectorizer to convert text to numerical\n",
        "# Extract system calls\n",
        "vectorizer = CountVectorizer()\n",
        "system_call_features = vectorizer.fit_transform(data['system_calls']).toarray()\n",
        "system_call_feature_names = [f\"system_call_{i}\" for i in range(system_call_features.shape[1])]\n",
        "system_call_df = pd.DataFrame(system_call_features, columns=system_call_feature_names)\n",
        "\n",
        "# Extract file changes\n",
        "vectorizer = CountVectorizer()\n",
        "file_change_features = vectorizer.fit_transform(data['file_changes']).toarray()\n",
        "file_change_feature_names = [f\"file_change_{i}\" for i in range(file_change_features.shape[1])]\n",
        "file_change_df = pd.DataFrame(file_change_features, columns=file_change_feature_names)\n",
        "\n",
        "# Extract network traffic patterns\n",
        "vectorizer = CountVectorizer()\n",
        "network_traffic_features = vectorizer.fit_transform(data['network_traffic']).toarray()\n",
        "network_traffic_feature_names = [f\"network_traffic_{i}\" for i in range(network_traffic_features.shape[1])]\n",
        "network_traffic_df = pd.DataFrame(network_traffic_features, columns=network_traffic_feature_names)\n",
        "\n",
        "# each unique token is a feature\n",
        "# Combine extracted features with the original dataset\n",
        "data = pd.concat([data, system_call_df, file_change_df, network_traffic_df], axis=1)\n",
        "\n",
        "# Drop the original raw columns as they are now encoded\n",
        "data.drop(columns=['system_calls', 'file_changes', 'network_traffic'], inplace=True)\n",
        "\n",
        "# normalize and Feature Scaling\n",
        "# will make them have a mean of 0 and stadndard deviation of 1\n",
        "scaler = StandardScaler()\n",
        "numerical_features = ['cpu_usage', 'memory_usage', 'network_activity']\n",
        "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
        "\n",
        "# One-hot Encoding for categorical variables, convert variables into binary\n",
        "categorical_features = ['protocol', 'device_type']\n",
        "encoder = OneHotEncoder()\n",
        "encoded_features = encoder.fit_transform(data[categorical_features]).toarray()\n",
        "\n",
        "# Combine encoded features with the dataset\n",
        "encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names)\n",
        "data = pd.concat([data, encoded_df], axis=1)\n",
        "data.drop(columns=categorical_features, inplace=True)\n",
        "\n",
        "# Split data into training, validation, and testing sets\n",
        "# training = 70%, validation = 15%(evaluate by tuning parameters after training on the training data), testing = 15%\n",
        "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "# Save processed datasets without including index column\n",
        "train_data.to_csv('train_data.csv', index=False)\n",
        "val_data.to_csv('val_data.csv', index=False)\n",
        "test_data.to_csv('test_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "BB68dSMguRF7",
        "outputId": "bfcf2d70-c101-4f54-8627-c729b59b664f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'rootkit_malware_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-74fa15a76e44>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load dataset from csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rootkit_malware_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Remove duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rootkit_malware_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization (QAOA) and tuning weight for penalty\n",
        "\n"
      ],
      "metadata": {
        "id": "WUU0k_eXxnEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from qiskit import Aer, execute\n",
        "from qiskit.circuit.library import QAOAAnsatz\n",
        "from qiskit.optimization import QuadraticProgram\n",
        "from qiskit.optimization.algorithms import MinimumEigenOptimizer\n",
        "from qiskit.aqua.algorithms import QAOA\n",
        "from qiskit.aqua import QuantumInstance\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Example data and feature importance (dummy data)\n",
        "n_features = 10\n",
        "feature_importance = np.random.rand(n_features)\n",
        "accuracy_weights = np.random.rand(n_features)  # Weights based on feature importance for accuracy\n",
        "\n",
        "# Define the Quadratic Program\n",
        "def define_quadratic_program(alpha, beta):\n",
        "    qp = QuadraticProgram()\n",
        "    for i in range(n_features):\n",
        "        qp.binary_var(name=f'x{i}')\n",
        "    objective = alpha * accuracy_weights - beta\n",
        "    qp.maximize(linear=objective)\n",
        "    return qp\n",
        "\n",
        "# QAOA ansatz and quantum instance\n",
        "qaoa_ansatz = QAOAAnsatz(optimizer='COBYLA')\n",
        "backend = Aer.get_backend('qasm_simulator')\n",
        "quantum_instance = QuantumInstance(backend, shots=1024)\n",
        "\n",
        "# Solve using QAOA\n",
        "def solve_qaoa(qp):\n",
        "    qaoa = QAOA(qaoa_ansatz, quantum_instance)\n",
        "    optimizer = MinimumEigenOptimizer(qaoa)\n",
        "    result = optimizer.solve(qp)\n",
        "    selected_features = [i for i, x in enumerate(result.x) if x > 0.5]\n",
        "    return selected_features\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(selected_features, X, y):\n",
        "    X_selected = X[:, selected_features]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "    # Train a simple classifier (e.g., logistic regression) and evaluate accuracy\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Tuning function\n",
        "def tune_weights(X, y, alpha_range, beta_range, cv_folds=3):\n",
        "    best_alpha = None\n",
        "    best_beta = None\n",
        "    best_score = -np.inf\n",
        "\n",
        "    for alpha in alpha_range:\n",
        "        for beta in beta_range:\n",
        "            qp = define_quadratic_program(alpha, beta)\n",
        "            kf = KFold(n_splits=cv_folds)\n",
        "            avg_accuracy = 0\n",
        "            avg_features = 0\n",
        "\n",
        "            for train_index, test_index in kf.split(X):\n",
        "                X_train, X_val = X[train_index], X[test_index]\n",
        "                y_train, y_val = y[train_index], y[test_index]\n",
        "\n",
        "                selected_features = solve_qaoa(qp)\n",
        "                accuracy = evaluate_model(selected_features, X_train, y_train)\n",
        "                avg_accuracy += accuracy / cv_folds\n",
        "                avg_features += len(selected_features) / cv_folds\n",
        "\n",
        "            composite_score = alpha * avg_accuracy - beta * avg_features\n",
        "            if composite_score > best_score:\n",
        "                best_score = composite_score\n",
        "                best_alpha = alpha\n",
        "                best_beta = beta\n",
        "\n",
        "    return best_alpha, best_beta\n",
        "\n",
        "# Example usage\n",
        "X = np.random.rand(100, n_features)  # Dummy feature data\n",
        "y = np.random.randint(0, 2, 100)  # Dummy target data\n",
        "alpha_range = np.linspace(0.1, 1.0, 10)\n",
        "beta_range = np.linspace(0.01, 0.1, 10)\n",
        "\n",
        "best_alpha, best_beta = tune_weights(X, y, alpha_range, beta_range)\n",
        "print(\"Best alpha:\", best_alpha)\n",
        "print(\"Best beta:\", best_beta)\n"
      ],
      "metadata": {
        "id": "PN0w_3HWxwk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO COMPARE COMPOSITE SCORE BEFORE AND AFTER OPTIMIZATION.\n",
        "\n",
        "HIGHER COMPOSITE = BETTER PERFORMANCE"
      ],
      "metadata": {
        "id": "O2DcsSpwx4_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a baseline alpha and beta\n",
        "baseline_alpha = 0.5\n",
        "baseline_beta = 0.05\n",
        "\n",
        "# Calculate the initial composite score\n",
        "def initial_composite_score(X, y, alpha, beta, cv_folds=3):\n",
        "    qp = define_quadratic_program(alpha, beta)\n",
        "    kf = KFold(n_splits=cv_folds)\n",
        "    avg_accuracy = 0\n",
        "    avg_features = 0\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_val = X[train_index], X[test_index]\n",
        "        y_train, y_val = y[train_index], y[test_index]\n",
        "\n",
        "        selected_features = solve_qaoa(qp)\n",
        "        accuracy = evaluate_model(selected_features, X_train, y_train)\n",
        "        avg_accuracy += accuracy / cv_folds\n",
        "        avg_features += len(selected_features) / cv_folds\n",
        "\n",
        "    composite_score = alpha * avg_accuracy - beta * avg_features\n",
        "    return composite_score\n",
        "\n",
        "initial_score = initial_composite_score(X, y, baseline_alpha, baseline_beta)\n",
        "print(\"Initial composite score:\", initial_score)\n",
        "\n",
        "# Perform tuning to find the best alpha and beta\n",
        "best_alpha, best_beta = tune_weights(X, y, alpha_range, beta_range)\n",
        "print(\"Best alpha:\", best_alpha)\n",
        "print(\"Best beta:\", best_beta)\n",
        "\n",
        "# Calculate the post-optimization composite score\n",
        "optimized_score = initial_composite_score(X, y, best_alpha, best_beta)\n",
        "print(\"Optimized composite score:\", optimized_score)\n",
        "\n",
        "# Compare scores\n",
        "improvement = optimized_score - initial_score\n",
        "print(\"Improvement in composite score:\", improvement)\n"
      ],
      "metadata": {
        "id": "OTw6MRgux_ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Train ML model"
      ],
      "metadata": {
        "id": "dHHfeIBXyGbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load and preprocess your dataset (assuming data is preprocessed and split into X_train, X_test, y_train, y_test)\n",
        "# Example:\n",
        "# X_train = pd.read_csv('X_train.csv')\n",
        "# X_test = pd.read_csv('X_test.csv')\n",
        "# y_train = pd.read_csv('y_train.csv')\n",
        "# y_test = pd.read_csv('y_test.csv')\n",
        "\n",
        "# Select features\n",
        "X_train_selected = X_train[:, selected_features]\n",
        "X_test_selected = X_test[:, selected_features]\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_selected)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "W2-pf8yayIPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}